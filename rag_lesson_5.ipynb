{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be55cc1272209248",
   "metadata": {},
   "source": [
    "## 1. 模块库的引入"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0067478-6686-4464-882f-1c880cd6c25a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:23.943858Z",
     "start_time": "2025-03-12T09:15:21.186260Z"
    }
   },
   "source": [
    "import faiss  # faiss向量库\n",
    "import numpy as np  # 处理嵌入向量数据，用于faiss向量检索\n",
    "import os  # 引入操作系统库，后续配置环境变量和获取文件路径\n",
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders import *  # 导入各种类型文档加载器类\n",
    "from langchain.text_splitter import *  # 导入各种文档分块类\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # 不使用分词并行化操作，避免多线程或多进程环境中运行多个模型引发冲突\n",
    "\n",
    "# 设置Qwen系列具体模型及对应的调用API密钥，从硅基流动大模型服务平台获得\n",
    "chat_model = os.getenv('chat_model')\n",
    "embed_model = os.getenv('embed_model')\n",
    "api_key = os.getenv('api_key')\n",
    "base_url = os.getenv('base_url')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "867cf12314c515b8",
   "metadata": {},
   "source": "## 2. 索引流程"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 加载文档",
   "id": "d6f022aac84ce6ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:23.957467Z",
     "start_time": "2025-03-12T09:15:23.950066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_document(file_path):\n",
    "    \"\"\"\n",
    "    解析各种文档格式的文件，返回文档内容字符串\n",
    "    :param file_path: 文档文件路径\n",
    "    :return: 返回文档内容的字符串\n",
    "    \"\"\"\n",
    "    # 定义文档解析加载器字典，根据文档类型选择对应的文档解析加载器类和输入参数\n",
    "    DOCUMENT_LOADER_MAPPING = {\n",
    "        \".pdf\": (PDFPlumberLoader, {}),\n",
    "        \".txt\": (TextLoader, {\"encoding\": \"utf8\"}),\n",
    "        \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "        \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "        \".ppt\": (UnstructuredPowerPointLoader, {}),\n",
    "        \".pptx\": (UnstructuredPowerPointLoader, {}),\n",
    "        \".xlsx\": (UnstructuredExcelLoader, {}),\n",
    "        \".csv\": (CSVLoader, {}),\n",
    "        \".md\": (UnstructuredMarkdownLoader, {}),\n",
    "        \".xml\": (UnstructuredXMLLoader, {}),\n",
    "        \".html\": (UnstructuredHTMLLoader, {})\n",
    "    }\n",
    "    ext = os.path.splitext(file_path)[1]  # 获取文件扩展名，确定文档类型\n",
    "    loader_tuple = DOCUMENT_LOADER_MAPPING.get(ext)  # 获取文档对应的文档解析加载器类和参数元组\n",
    "\n",
    "    if loader_tuple:  # 判断文档格式是否在加载器支持范围\n",
    "        loader_class, loader_args = loader_tuple  # 解包元组，获取文档解析加载器类和参数\n",
    "        loader = loader_class(file_path, **loader_args)  # 创建文档解析加载器实例，并传入文档文件路径\n",
    "        documents = loader.load()  # 加载文档\n",
    "        content = \"\\n\".join([doc.page_content for doc in documents])  # 多页文档内容组合为字符串\n",
    "        print(f\"文档{file_path}的部分内容为: {content[:100]}...\")  # 仅用来展示文档内容的前100个字符\n",
    "        return content  # 返回文档内容的多页拼合字符串\n",
    "    print(file_path+f\". 不支持的文档类型: '{ext}'\")  # 若文件格式不支持，输出信息，返回空字符串.\n",
    "    return \"\"\n"
   ],
   "id": "bd712617008cb038",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 获取文本嵌入",
   "id": "e27aed166830c785"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.446458Z",
     "start_time": "2025-03-12T09:15:24.440741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_embedding_model():\n",
    "    \"\"\"\n",
    "    加载bge-m3模型\n",
    "    :return: 返回bge-m3模型嵌入的结果\n",
    "    \"\"\"\n",
    "    client = OpenAI(\n",
    "            api_key=api_key, # 从https://cloud.siliconflow.cn/account/ak获取\n",
    "            base_url=base_url\n",
    "        )\n",
    "    print(f\"加载Embedding模型中\")\n",
    "\n",
    "    def get_embedding(text):\n",
    "       text = text.replace(\"\\n\", \" \")\n",
    "       return client.embeddings.create(input = [text], model=embed_model).data[0].embedding\n",
    "\n",
    "    # from sentence_transformers import SentenceTransformer\n",
    "    # get_embedding = SentenceTransformer(os.path.abspath('data/bge-large-zh-v1.5'))\n",
    "    # print(f\"bge-small-zh-v1.5模型最大输入长度: {get_embedding.max_seq_length}\")\n",
    "\n",
    "    return get_embedding"
   ],
   "id": "daa9fec27d0973aa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 建立索引，即把文本嵌入写入FAISS向量数据库",
   "id": "54e0ccf4455ff89b"
  },
  {
   "cell_type": "code",
   "id": "7a5bcf10be91c245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.471312Z",
     "start_time": "2025-03-12T09:15:24.462024Z"
    }
   },
   "source": [
    "def indexing_process(folder_path, embedding_model, collection):\n",
    "    \"\"\"\n",
    "    索引流程：加载PDF文件，并将其内容分割成小块，计算这些小块的嵌入向量并将其存储在chromadb向量数据库中。\n",
    "    :param folder_path: 文档文件路径\n",
    "    :param embedding_model: 预加载的嵌入模型\n",
    "    :param collection: chroma_db表，存储id，embedding，chunk\n",
    "    \"\"\"\n",
    "    # 初始化空的chunks列表，用于存储所有文档文件的文本块\n",
    "    all_chunks = []\n",
    "    all_ids = []\n",
    "\n",
    "    # 遍历文件夹中的所有文档文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename) # 检查是否为文件\n",
    "        if os.path.isfile(file_path):\n",
    "            # 解析文档文件，获得文档字符串内容\n",
    "            document_text = load_document(file_path)\n",
    "            print(f\"文档 {filename} 的总字符数: {len(document_text)}\")\n",
    "\n",
    "            # todo 配置SpacyTextSplitter分割文本块库\n",
    "            #text_splitter = SpacyTextSplitter(\n",
    "            #    chunk_size=512, chunk_overlap=128, pipeline=\"zh_core_web_sm\")\n",
    "\n",
    "            # 配置RecursiveCharacterTextSplitter分割文本块库参数，每个文本块的大小为512字符（非token），相邻文本块之间的重叠128字符（非token）\n",
    "            # todo 可以更换为CharacterTextSplitter、MarkdownTextSplitter、PythonCodeTextSplitter、LatexTextSplitter、NLTKTextSplitter等\n",
    "            text_splitter = RecursiveCharacterTextSplitter( chunk_size=512, chunk_overlap=128 )\n",
    "            # 将文档文本分割成文本块Chunk\n",
    "            chunks = text_splitter.split_text(document_text)\n",
    "            print(f\"文档 {filename} 分割的文本Chunk数量: {len(chunks)}\")\n",
    "            # 将分割的文本块添加到总chunks列表中\n",
    "            all_chunks.extend(chunks)\n",
    "            # 将分割的文本块id添加到总ids列表中\n",
    "            all_ids.extend([str(uuid.uuid4()) for _ in range(len(chunks))])\n",
    "\n",
    "    # 文本块转化为嵌入向量列表，用于计算相似度\n",
    "    embeddings = [embedding_model(chunk) for chunk in all_chunks]\n",
    "    # embeddings = [embedding_model.encode(chunk, normalize_embeddings=True).tolist() for chunk in all_chunks]\n",
    "\n",
    "    # collection.add(ids=all_ids, embeddings=embeddings, documents=all_chunks)\n",
    "    collection.add(ids=list(map(str, range(len(all_chunks)))), embeddings=embeddings, documents=all_chunks)\n",
    "    print(\"文本块Chunk转化为嵌入向量完成\")\n",
    "    print(\"索引过程完成\")\n",
    "    print(\"*\" * 100)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. 检索流程",
   "id": "bb8e383da8038290"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.501577Z",
     "start_time": "2025-03-12T09:15:24.492176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieval_process(query, collection, embedding_model, top_k=3):\n",
    "    \"\"\"\n",
    "    检索流程：将用户查询Query转化为嵌入向量，并在Chroma索引中检索最相似的前k个文本块。\n",
    "    :param query: 用户查询语句\n",
    "    :param collection: chroma_db表，存储了id，embedding，chunk\n",
    "    :param embedding_model: 预加载的嵌入模型\n",
    "    :param top_k: 返回最相似的前K个结果\n",
    "    :return: 返回最相似的文本块及其相似度得分\n",
    "    \"\"\"\n",
    "    # todo 向量检索流程\n",
    "    # 将查询转化为嵌入向量\n",
    "    query_embedding = embedding_model(query)\n",
    "    results = collection.query(query_embeddings=query_embedding, n_results=top_k)\n",
    "\n",
    "    print(f\"查询语句: {query}\")\n",
    "    print(f\"向量检索最相似的前{top_k}个文本块:\")\n",
    "    vector_chunks = []\n",
    "    # 打印检索到的文本块ID、相似度和文本块信息\n",
    "    for doc_id, doc, score in zip(results['ids'][0], results['documents'][0], results['distances'][0]):\n",
    "        print(f\"文本块ID: {doc_id}\")\n",
    "        print(f\"相似度: {score}\")\n",
    "        print(f\"文本块信息:\\n{doc}\\n\")\n",
    "        vector_chunks.append(doc)\n",
    "\n",
    "    # todo 关键字检索流程\n",
    "    # 获取向量数据库中所有文本块\n",
    "    all_docs = collection.get()['documents']\n",
    "    # 使用jieba分词对所有文本块进行分词\n",
    "    tokenized_corpus = [list(jieba.cut(doc)) for doc in all_docs]\n",
    "    # 获取所有分词结果的bm25查询引擎\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    # 对查询语句进行分词\n",
    "    tokenized_query = list(jieba.cut(query))\n",
    "    # 计算BM25得分\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    # 获取BM25得分最高的top_k个文本块的索引\n",
    "    bm25_topk_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "    bm25_chunks = [all_docs[i] for i in bm25_topk_indices]\n",
    "    print(f\"关键字检索最相似的前{top_k}个文本块:\")\n",
    "    for i, chunk in zip(bm25_topk_indices, bm25_chunks):\n",
    "        print(f\"文本块ID: {i}\")\n",
    "        print(f\"BM25得分: {bm25_scores[i]}\")\n",
    "        print(f\"文本块信息:\\n{chunk}\\n\")\n",
    "\n",
    "    retrieved_chunks = list(set(vector_chunks + bm25_chunks))\n",
    "\n",
    "    print(\"检索过程完成.\")\n",
    "    print(\"*\" * 100)\n",
    "    return retrieved_chunks"
   ],
   "id": "c17d1ee1ebd2d3ad",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. 生成流程",
   "id": "37757a835a152adc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.547464Z",
     "start_time": "2025-03-12T09:15:24.540227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_process(query, chunks):\n",
    "    \"\"\"\n",
    "    生成流程：调用Qwen大模型云端API，根据查询和文本块生成最终回复。\n",
    "    :param query: 用户查询语句\n",
    "    :param chunks: 从检索过程中获得的相关文本块上下文chunks\n",
    "    :return: 返回生成的响应内容\n",
    "    \"\"\"\n",
    "    # 构建参考文档内容，格式为“参考文档1: \\n 参考文档2: \\n ...”等\n",
    "    context = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        context += f\"参考文档{i+1}: \\n{chunk}\\n\\n\"\n",
    "\n",
    "    # 构建生成模型所需的Prompt，包含用户查询和检索到的上下文\n",
    "    prompt = f\"根据参考文档回答问题：{query}\\n\\n{context}\"\n",
    "    # print(f\"生成模型的Prompt: {prompt}\")\n",
    "\n",
    "    # 准备请求消息，将prompt作为输入\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "\n",
    "    # 调用大模型API实例化大语言模型\n",
    "    client = OpenAI(\n",
    "        api_key=api_key, # 从https://cloud.siliconflow.cn/account/ak获取\n",
    "        base_url=base_url\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 使用大模型生成响应\n",
    "        responses = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        messages = messages,\n",
    "        temperature=0.01,\n",
    "        top_p=0.95,\n",
    "        stream=False,\n",
    "        )\n",
    "\n",
    "        print(\"生成过程开始:\")\n",
    "        # 流式响应\n",
    "        # 初始化变量以存储生成的响应内容\n",
    "        # generated_response = \"\"\n",
    "\n",
    "        # # 逐步获取和处理模型的增量输出\n",
    "        # for response in responses:\n",
    "        #     response = response.choices[0].delta.content\n",
    "        #     if response is not None:\n",
    "        #         generated_response+=response\n",
    "        #         print(response, end=\"\")\n",
    "\n",
    "        # 非流式响应\n",
    "        generated_response = responses.choices[0].message.content\n",
    "        print(generated_response)\n",
    "\n",
    "        print(\"\\n生成过程完成.\")\n",
    "        return generated_response\n",
    "    except Exception as e:\n",
    "        print(f\"大模型生成过程中发生错误: {e}\")\n",
    "        return None"
   ],
   "id": "a6905578d4df5daa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. 执行整个流程",
   "id": "79bb2b8ae729f8aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.566477Z",
     "start_time": "2025-03-12T09:15:24.560479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"RAG过程开始.\")\n",
    "query=\"下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？\""
   ],
   "id": "34b6aff568263809",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG过程开始.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. 执行索引过程",
   "id": "9508e1e0816b7479"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:24.589618Z",
     "start_time": "2025-03-12T09:15:24.584210Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install -U pip chromadb langchain langchain_community sentence-transformers unstructured pdfplumber python-docx python-pptx markdown openpyxl pandas -i https://pypi.tuna.tsinghua.edu.cn/simple",
   "id": "d37687522515bd22",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:25.209091Z",
     "start_time": "2025-03-12T09:15:24.605749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chromadb # 引入 Chroma 向量数据库\n",
    "import uuid # 生成唯一ID\n",
    "import shutil # 文件操作模块，为了避免既往数据的干扰，在每次启动时清空 ChromaDB 存储目录中的文件"
   ],
   "id": "13043a4aa27992a9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7ee913c5-b621-451e-bd9f-0a1956aff4e2",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:30.585124Z",
     "start_time": "2025-03-12T09:15:25.224467Z"
    }
   },
   "source": [
    "embedding_model = load_embedding_model()\n",
    "\n",
    "# 为了避免既往数据的干扰，在每次启动时清空 ChromaDB 存储目录中的文件\n",
    "chroma_db_path = os.path.abspath(\"chroma_db\")\n",
    "if os.path.exists(chroma_db_path):\n",
    "    shutil.rmtree(chroma_db_path)\n",
    "\n",
    "# 创建ChromaDB实例和集合collection\n",
    "client = chromadb.PersistentClient(chroma_db_path)\n",
    "collection = client.get_or_create_collection(name=\"documents\")\n",
    "\n",
    "# 索引流程：加载PDF文件，分割文本块，计算嵌入向量，存储在FAISS向量库中（内存）\n",
    "indexing_process('data', embedding_model, collection)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载Embedding模型中\n",
      "文档data\\lesson1.pdf的部分内容为: 数字化转型\n",
      "1. 数字化转型的背景和意义\n",
      "1.1 背景\n",
      "在过去的十年里，数字技术的迅猛发展已彻底改变了企业运营的方方面面。互联网、移动技\n",
      "术、云计算、大数据、物联网（IoT）以及人工智能（AI）等技术...\n",
      "文档 lesson1.pdf 的总字符数: 9165\n",
      "文档 lesson1.pdf 分割的文本Chunk数量: 26\n",
      "文本块Chunk转化为嵌入向量完成\n",
      "索引过程完成\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. 执行检索过程",
   "id": "fdf91d4bab4a4b09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:30.603975Z",
     "start_time": "2025-03-12T09:15:30.600506Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install jieba rank-bm25",
   "id": "d46d641d3beb2d15",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:30.656491Z",
     "start_time": "2025-03-12T09:15:30.632751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jieba\n",
    "from rank_bm25 import BM25Okapi\n",
    "import logging\n",
    "\n",
    "# 禁用 jieba 的日志输出\n",
    "jieba.setLogLevel(logging.WARNING)"
   ],
   "id": "34d37a0004826c67",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:31.584005Z",
     "start_time": "2025-03-12T09:15:30.672765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检索流程：将用户查询转化为嵌入向量，检索最相似的文本块\n",
    "retrieval_chunks = retrieval_process(query, collection, embedding_model)"
   ],
   "id": "8f1a6cb6c1ff99f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询语句: 下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？\n",
      "向量检索最相似的前3个文本块:\n",
      "文本块ID: 23\n",
      "相似度: 0.91958567390902\n",
      "文本块信息:\n",
      "构建基于云计算的智能供应链管理系统，实现供应链的端到端可视化管理。\n",
      "2.2 案例二：零售业的数字化转型\n",
      "2.2.1 公司背景\n",
      "零售业案例讲述了一家全球知名的快时尚服装零售企业，面对电子商务的崛起和消费者购物\n",
      "行为的快速变化，传统零售模式受到巨大挑战。为保持市场竞争力并满足消费者日益增长的\n",
      "数字化需求，公司决定实施全面的数字化转型战略。\n",
      "2.2.2 面临的挑战\n",
      "在数字化转型之前，零售业案例的公司面临以下挑战：线上线下渠道割裂，导致库存管理不\n",
      "统一、客户体验不一致，难以提供无缝购物体验；数据利用率低，尽管拥有大量消费者和销\n",
      "售数据，但缺乏先进的数据分析工具，未能转化为可操作的商业洞察。\n",
      "\n",
      "文本块ID: 22\n",
      "相似度: 0.9451326041044928\n",
      "文本块信息:\n",
      "2. 案例分析\n",
      "2.1 案例一：制造业的数字化转型\n",
      "2.1.1 公司背景\n",
      "制造业案例介绍了一家成立于20世纪初的德国老牌汽车制造公司，拥有悠久的历史和丰富\n",
      "的制造经验。面对日益激烈的市场竞争和消费者需求的变化，公司意识到传统制造模式已无\n",
      "法适应现代市场需求，因而决定实施全面的数字化转型，以保持竞争力。\n",
      "2.1.2 面临的挑战\n",
      "在数字化转型之前，制造业案例公司面临多重挑战：生产效率低下，传统制造流程依赖人工，\n",
      "导致效率低且易出错；供应链复杂，涉及多个国家和地区，信息传递不及时，造成库存管理\n",
      "困难，甚至存在供应链断裂的风险；客户需求变化快，传统大规模生产方式无法满足市场对\n",
      "个性化定制产品的需求。\n",
      "2.1.3 数字化转型解决方案\n",
      "为了应对制造业上述挑战，公司通过以下步骤进行数字化转型：首先，引入工业4.0技术，\n",
      "包括物联网（IoT）、人工智能（AI）、大数据分析和机器人自动化，以优化生产线；其次，\n",
      "构建基于云计算的智能供应链管理系统，实现供应链的端到端可视化管理。\n",
      "2.2 案例二：零售业的数字化转型\n",
      "2.2.1 公司背景\n",
      "零售业案例讲述了一家全球知名的快时尚服装零售企业，面对电子商务的崛起和消费者购物\n",
      "\n",
      "文本块ID: 24\n",
      "相似度: 0.9626499204392852\n",
      "文本块信息:\n",
      "2.2.3 数字化转型解决方案\n",
      "为了解决零售业案例的线上线下渠道割裂、数据利用率低、供应链效率低下和客户体验滞后\n",
      "等问题，公司实施了一系列数字化转型措施：首先，构建全渠道零售平台，实现线上与线下\n",
      "购物渠道的无缝整合，提升顾客的便利性和满意度；其次，引入大数据和人工智能驱动的分\n",
      "析平台，精准预测需求、优化库存，并提供个性化产品推荐和营销活动。\n",
      "2.3 案例三：金融业的数字化转型\n",
      "2.3.1 公司背景\n",
      "金融业案例中的金融机构是一家全球知名的银行，成立已有百年历史。随着金融科技\n",
      "（FinTech）的迅速发展以及消费者对在线金融服务需求的增加，传统银行业务模式面临前\n",
      "所未有的挑战。为了保持市场竞争力并满足客户日益增长的数字化需求，该银行决定开展全\n",
      "面的数字化转型。\n",
      "2.3.2 面临的挑战\n",
      "在数字化转型之前，金融业案例中银行面临以下主要挑战：客户服务模式过时，主要依赖实\n",
      "体网点，导致服务效率低、客户体验差；金融科技企业带来巨大竞争压力，凭借创新技术和\n",
      "便捷服务吸引大量客户，尤其是年轻一代；数据孤岛和风险管理滞后，各业务部门缺乏数据\n",
      "共享机制，导致信息无法整合，风险管理效率低。\n",
      "2.3.3 数字化转型解决方案\n",
      "\n",
      "关键字检索最相似的前3个文本块:\n",
      "文本块ID: 22\n",
      "BM25得分: 12.604925793261192\n",
      "文本块信息:\n",
      "2. 案例分析\n",
      "2.1 案例一：制造业的数字化转型\n",
      "2.1.1 公司背景\n",
      "制造业案例介绍了一家成立于20世纪初的德国老牌汽车制造公司，拥有悠久的历史和丰富\n",
      "的制造经验。面对日益激烈的市场竞争和消费者需求的变化，公司意识到传统制造模式已无\n",
      "法适应现代市场需求，因而决定实施全面的数字化转型，以保持竞争力。\n",
      "2.1.2 面临的挑战\n",
      "在数字化转型之前，制造业案例公司面临多重挑战：生产效率低下，传统制造流程依赖人工，\n",
      "导致效率低且易出错；供应链复杂，涉及多个国家和地区，信息传递不及时，造成库存管理\n",
      "困难，甚至存在供应链断裂的风险；客户需求变化快，传统大规模生产方式无法满足市场对\n",
      "个性化定制产品的需求。\n",
      "2.1.3 数字化转型解决方案\n",
      "为了应对制造业上述挑战，公司通过以下步骤进行数字化转型：首先，引入工业4.0技术，\n",
      "包括物联网（IoT）、人工智能（AI）、大数据分析和机器人自动化，以优化生产线；其次，\n",
      "构建基于云计算的智能供应链管理系统，实现供应链的端到端可视化管理。\n",
      "2.2 案例二：零售业的数字化转型\n",
      "2.2.1 公司背景\n",
      "零售业案例讲述了一家全球知名的快时尚服装零售企业，面对电子商务的崛起和消费者购物\n",
      "\n",
      "文本块ID: 24\n",
      "BM25得分: 12.010488993513079\n",
      "文本块信息:\n",
      "2.2.3 数字化转型解决方案\n",
      "为了解决零售业案例的线上线下渠道割裂、数据利用率低、供应链效率低下和客户体验滞后\n",
      "等问题，公司实施了一系列数字化转型措施：首先，构建全渠道零售平台，实现线上与线下\n",
      "购物渠道的无缝整合，提升顾客的便利性和满意度；其次，引入大数据和人工智能驱动的分\n",
      "析平台，精准预测需求、优化库存，并提供个性化产品推荐和营销活动。\n",
      "2.3 案例三：金融业的数字化转型\n",
      "2.3.1 公司背景\n",
      "金融业案例中的金融机构是一家全球知名的银行，成立已有百年历史。随着金融科技\n",
      "（FinTech）的迅速发展以及消费者对在线金融服务需求的增加，传统银行业务模式面临前\n",
      "所未有的挑战。为了保持市场竞争力并满足客户日益增长的数字化需求，该银行决定开展全\n",
      "面的数字化转型。\n",
      "2.3.2 面临的挑战\n",
      "在数字化转型之前，金融业案例中银行面临以下主要挑战：客户服务模式过时，主要依赖实\n",
      "体网点，导致服务效率低、客户体验差；金融科技企业带来巨大竞争压力，凭借创新技术和\n",
      "便捷服务吸引大量客户，尤其是年轻一代；数据孤岛和风险管理滞后，各业务部门缺乏数据\n",
      "共享机制，导致信息无法整合，风险管理效率低。\n",
      "2.3.3 数字化转型解决方案\n",
      "\n",
      "文本块ID: 23\n",
      "BM25得分: 10.214723436927384\n",
      "文本块信息:\n",
      "构建基于云计算的智能供应链管理系统，实现供应链的端到端可视化管理。\n",
      "2.2 案例二：零售业的数字化转型\n",
      "2.2.1 公司背景\n",
      "零售业案例讲述了一家全球知名的快时尚服装零售企业，面对电子商务的崛起和消费者购物\n",
      "行为的快速变化，传统零售模式受到巨大挑战。为保持市场竞争力并满足消费者日益增长的\n",
      "数字化需求，公司决定实施全面的数字化转型战略。\n",
      "2.2.2 面临的挑战\n",
      "在数字化转型之前，零售业案例的公司面临以下挑战：线上线下渠道割裂，导致库存管理不\n",
      "统一、客户体验不一致，难以提供无缝购物体验；数据利用率低，尽管拥有大量消费者和销\n",
      "售数据，但缺乏先进的数据分析工具，未能转化为可操作的商业洞察。\n",
      "\n",
      "检索过程完成.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. 生成回答",
   "id": "a574a71d71196272"
  },
  {
   "cell_type": "code",
   "id": "da8e1e60e850c583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:46.428341Z",
     "start_time": "2025-03-12T09:15:31.613027Z"
    }
   },
   "source": [
    "# 生成流程：调用Qwen大模型生成响应\n",
    "generate_process(query, retrieval_chunks)\n",
    "\n",
    "print(\"RAG过程结束.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成过程开始:\n",
      "根据提供的参考文档，报告中涉及了三个行业的案例，分别是制造业、零售业和金融业。每个行业面临的挑战如下：\n",
      "\n",
      "1. **制造业**：\n",
      "   - 生产效率低下，传统制造流程依赖人工，导致效率低且易出错。\n",
      "   - 供应链复杂，涉及多个国家和地区，信息传递不及时，造成库存管理困难，甚至存在供应链断裂的风险。\n",
      "   - 客户需求变化快，传统大规模生产方式无法满足市场对个性化定制产品的需求。\n",
      "\n",
      "2. **零售业**：\n",
      "   - 线上线下渠道割裂，导致库存管理不统一、客户体验不一致，难以提供无缝购物体验。\n",
      "   - 数据利用率低，尽管拥有大量消费者和销售数据，但缺乏先进的数据分析工具，未能转化为可操作的商业洞察。\n",
      "\n",
      "3. **金融业**：\n",
      "   - 客户服务模式过时，主要依赖实体网点，导致服务效率低、客户体验差。\n",
      "   - 金融科技企业带来巨大竞争压力，凭借创新技术和便捷服务吸引大量客户，尤其是年轻一代。\n",
      "   - 数据孤岛和风险管理滞后，各业务部门缺乏数据共享机制，导致信息无法整合，风险管理效率低。\n",
      "\n",
      "生成过程完成.\n",
      "RAG过程结束.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:15:46.445070Z",
     "start_time": "2025-03-12T09:15:46.442747Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d80474a81c72044f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag env",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
